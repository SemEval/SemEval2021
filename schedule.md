---
title: SemEval-2021 Program
---

## SemEval-2021: Program

[SemEval-2021](https://semeval.github.io/SemEval2021/) will be colocated with [ACL 2021](https://2021.aclweb.org/). All times shown are [UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time).

To accommodate different time zones, each poster session is held three times. **Emojis indicate when authors intend to be present at their poster.**

All SemEval papers can be found in the [__proceedings__](https://aclanthology.org/volumes/2021.semeval-1/).

### Thursday, August 5

<details><summary><strong>14:00-15:00 Invited Talk: Diyi Yang, <em>Seven Social Factors in Natural Language Processing: Theory and Practice</em></strong></summary>

  Recently, natural language processing (NLP) has had increasing success and produced extensive industrial applications. Despite being sufficient to enable these applications, current NLP systems often ignore the social part of language, e.g., who says it, in what context, for what goals. In this talk, we take a closer look at social factors in language via a new theory taxonomy, and its interplay with computational methods via two lines of work. The first one studies what makes language persuasive by introducing a semi-supervised method to leverage hierarchical structures in text to recognize persuasion strategies in good-faith requests. The second part demonstrates how various structures in conversations can be utilized to generate better summaries for everyday interaction. We conclude by discussing several open-ended questions towards how to build socially aware language technologies, with the hope of getting closer to the goal of human-like language understanding.

  Bio: Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech. She is broadly interested in Computational Social Science, and Natural Language Processing. Diyi received her PhD from the Language Technologies Institute at Carnegie Mellon University. Her work has been published at leading NLP/HCI conferences, and also resulted in multiple award nominations from EMNLP, ICWSM, SIGCHI and CSCW. She is named as a Forbes 30 under 30 in Science, a recipient of IEEE AI 10 to Watch, and has received faculty research awards from Amazon, Facebook, JPMorgan Chase, and Salesforce.
  
</details>

<details open><summary><strong>15:00-15:25 Plenary session: Tasks 1, 2, 4</strong></summary>

 - _SemEval-2021 Task 1: Lexical Complexity Prediction_, Matthew Shardlow, Richard Evans, Gustavo Henrique Paetzold and Marcos Zampieri
 - _OCHADAI-KYOTO at SemEval-2021 Task 1: Enhancing Model Generalization and Robustness for Lexical Complexity Prediction_, Yuki Taya, Lis Kanashiro Pereira, Fei Cheng and Ichiro Kobayashi
 - _SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)_, Federico Martelli, Najla Kalach, Gabriele Tola and Roberto Navigli
 - _SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning_, Boyuan Zheng, Xiaoyu Yang, Yu-Ping Ruan, Zhenhua Ling, Quan Liu, Si Wei and Xiaodan Zhu
 - _TA-MAMC at SemEval-2021 Task 4: Task-adaptive Pretraining and Multi-head Attention for Abstract Meaning Reading Comprehension_ Jing Zhang, Yimeng Zhuang and Yinpei Su

</details>

<details open><summary><strong>15:25-15:50 Plenary session: Tasks 5, 6, 7</strong></summary>

 - _SemEval-2021 Task 5: Toxic Spans Detection_, John Pavlopoulos, Jeffrey Sorensen, Léo Laugier and Ion Androutsopoulos
 - _SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and Images_, Dimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj Alam, Fabrizio Silvestri, Hamed Firooz, Preslav Nakov and Giovanni Da San Martino
 - _Alpha at SemEval-2021 Task 6: Transformer Based Propaganda Classification_, Zhida Feng, Jiji Tang, Jiaxiang Liu, Weichong Yin, Shikun Feng, Yu Sun and Li Chen
 - _SemEval 2021 Task 7: HaHackathon, Detecting and Rating Humor and Offense_, J. A. Meaney, Steven Wilson, Luis Chiruzzo, Adam Lopez and Walid Magdy

</details>

<details><summary><strong>15:50-16:00 Announcement of Best Paper Awards & General Discussion</strong></summary>
  To be announced!
</details>

<details><summary><strong>02:00-03:00(🌻) / 11:30-12:30(🌳) / 16:30-17:30(🍄) Poster session: Tasks 1, 2, 4</strong></summary>

 - #56 _LangResearchLab NC at SemEval-2021 Task 1: Linguistic Feature Based Modelling for Lexical Complexity_, Raksha Agarwal and Niladri Chatterjee 🌻🌳
 - #67 _OCHADAI-KYOTO at SemEval-2021 Task 1: Enhancing Model Generalization and Robustness for Lexical Complexity Prediction_, Yuki Taya, Lis Kanashiro Pereira, Fei Cheng and Ichiro Kobayashi 🌻
 - #123 _Complex words identification using word-level features for SemEval-2020 Task 1_, Jenny Ortiz-Zambrano and Arturo Montejo-Ráez 
 - #150 _TUDA-CCL at SemEval-2021 Task 1: Using Gradient-boosted Regression Tree Ensembles Trained on a Heterogeneous Feature Set for Predicting Lexical Complexity_, Sebastian Gombert and Sabine Bartsch 🌳🍄
 - #156 _JCT at SemEval-2021 Task 1: Context-aware Representation for Lexical Complexity Prediction_, Chaya Liebeskind, Otniel Elkayam and Shmuel Liebeskind 🌳🍄
 - #195 _IAPUCP at SemEval-2021 Task 1: Stacking Fine-Tuned Transformers is Almost All You Need for Lexical Complexity Prediction_, Kervy Rivas Rojas and Fernando Alva-Manchego 
 - #110 _Uppsala NLP at SemEval-2021 Task 2: Multilingual Language Models for Fine-tuning and Feature Extraction in Word-in-Context Disambiguation_, Huiling You, Xingran Zhu and Sara Stymne 🍄
 - #113 _SkoltechNLP at SemEval-2021 Task 2: Generating Cross-Lingual Training Data for the Word-in-Context Task_, Anton Razzhigaev, Nikolay Arefyev and Alexander Panchenko 
 - #191 _Zhestyatsky at SemEval-2021 Task 2: ReLU over Cosine Similarity for BERT Fine-tuning_, Boris Zhestiankin and Maria Ponomareva 🌳
 - #200 _SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation_, Gábor Berend 🌳🍄
 - #66 _ReCAM@IITK at SemEval-2021 Task 4: BERT and ALBERT based Ensemble for Abstract Word Prediction_, Abhishek Mittal and Ashutosh Modi 🌳
 - #136 _ECNU_ICA_1 SemEval-2021 Task 4: Leveraging Knowledge-enhanced Graph Attention Networks for Reading Comprehension of Abstract Meaning_, Pingsheng Liu, Linlin Wang, Qian Zhao, Hao Chen, Yuxi Feng, Xin Lin and liang he 
 - #137 _LRG at SemEval-2021 Task 4: Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting_, Abheesht Sharma, Harshit Pandey, Gunjan Chhablani, Yash Bhartia and Tirtharaj Dash 🌻🌳🍄
 - #165 _IIE-NLP-Eyas at SemEval-2021 Task 4: Enhancing PLM for ReCAM with Special Tokens, Re-Ranking, Siamese Encoders and Back Translation_, Yuqiang Xie, Luxi Xing, Wei Peng and Yue Hu 
 - #192 _TA-MAMC at SemEval-2021 Task 4: Task-adaptive Pretraining and Multi-head Attention for Abstract Meaning Reading Comprehension_, Jing Zhang, Yimeng Zhuang and Yinpei Su 🌻🍄
 - #207 _NLP-IIS@UT at SemEval-2021 Task 4: Machine Reading Comprehension using the Long Document Transformer_, Hossein Basafa, Sajad Movahedi, Ali Ebrahimi, Azadeh Shakery and Heshaam Faili 🌳

</details>

<details><summary><strong>03:00-04:00(🌻) / 12:30-13:30(🌳) / 17:30-18:30(🍄) Poster session: Tasks 5, 6, 7</strong></summary>

 - #18 _IITK@Detox at SemEval-2021 Task 5: Semi-Supervised Learning and Dice Loss for Toxic Spans Detection_, Archit Bansal, Abhay Kaushik and Ashutosh Modi 🌳
 - #37 _UniParma at SemEval-2021 Task 5: Toxic Spans Detection Using CharacterBERT and Bag-of-Words Model_, Akbar Karimi, Leonardo Rossi and Andrea Prati 🍄
 - #42 _UPB at SemEval-2021 Task 5: Virtual Adversarial Training for Toxic Spans Detection_, Andrei Paraschiv, Dumitru-Clementin Cercel and Mihai Dascalu 🌳
 - #45 _NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques_, Gunjan Chhablani, Abheesht Sharma, Harshit Pandey, Yash Bhartia and Shan Suthaharan 🌻🌳🍄
 - #85 _UoB at SemEval-2021 Task 5: Extending Pre-Trained Language Models to Include Task and Domain-Specific Information for Toxic Span Prediction_, Erik Yan and Harish Tayyar Madabushi 🌳
 - #90 _Cisco at SemEval-2021 Task 5: What’s Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments_, Sreyan Ghosh and Sonal Kumar 
 - #175 _MedAI at SemEval-2021 Task 5: Start-to-end Tagging Framework for Toxic Spans Detection_, Zhen Wang, Hongjie Fan and Junfei Liu 
 - #210 _HamiltonDinggg at SemEval-2021 Task 5: Investigating Toxic Span Detection using RoBERTa Pre-training_, Huiyang Ding and David Jurgens 🌳
 - #101 _Alpha at SemEval-2021 Task 6: Transformer Based Propaganda Classification_, Zhida Feng, Jiji Tang, Jiaxiang Liu, Weichong Yin, Shikun Feng, Yu Sun and Li Chen 🍄
 - #157 _WVOQ at SemEval-2021 Task 6: BART for Span Detection and Classification_, Cees Roele 🌳🍄
 - #55 _HumorHunter at SemEval-2021 Task 7: Humor and Offense Recognition with Disentangled Attention_, Yubo Xie, Junze Li and Pearl Pu 🍄
 - #92 _Grenzlinie at SemEval-2021 Task 7: Detecting and Rating Humor and Offense_, Renyuan Liu and Xiaobing Zhou 
 - #118 _abcbpc at SemEval-2021 Task 7: ERNIE-based Multi-task Model for Detecting and Rating Humor and Offense_, Chao Pang, Xiaoran Fan, Weiyue Su, Xuyi Chen, Shuohuan Wang, Jiaxiang Liu, Xuan Ouyang, Shikun Feng and Yu Sun 🌻
 - #129 _Humor@IITK at SemEval-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness_, Aishwarya Gupta, Avik Pal, Bholeshwar Khurana, Lakshay Tyagi and Ashutosh Modi 🌳
 - #201 _RoMa at SemEval-2021 Task 7: A Transformer-based Approach for Detecting and Rating Humor and Offense_, Roberto Labadie, Mariano Jason Rodriguez, Reynier Ortega and Paolo Rosso 🌳

</details>

### Friday, August 6

<details><summary><strong>14:00-15:00 Invited Talk: Hannah Rohde, <em>Predictability and Informativity in Communication</em></strong></summary>

  This talk brings a psycholinguistic perspective to the questions of what makes a 'good' sentence for a speaker (or NLG system) to produce and what makes a 'good' inference about the world for a listener (or NLU system) to draw from the sentences they encounter.   I consider the link between real-world predictability and text likelihood – do the things that speakers choose to say about the world provide a transparent mapping to how the world really is?  This talk will introduce experimental evidence that comprehenders expect speakers to mention newsworthy content (namely content that is not highly predictable from world knowledge). For example, comprehenders who are asked to guess what a speaker is going to say next will infer from the mention of the word 'yellow' that the speaker is unlikely to be talking about something prototypically yellow (they anticipate that the speaker is talking about a shirt instead of a banana) and, more generally, they will guess that a sentence contains content that deviates from their real-world priors (they anticipate a description of a newsworthy situation with properties that are rare in the real world).   Such findings have implications for the way we use text to infer meaningful facts about the world and the way we evaluate the felicity and sensibility of a text.

  Bio: Hannah Rohde is a Reader in Linguistics & English Language at the University of Edinburgh. She works in experimental pragmatics, using psycholinguistic techniques to investigate questions in areas such as pronoun interpretation, referring expression generation, implicature, presupposition, deception, and the establishment of discourse coherence.  Her undergraduate degree was in Computer Science and Linguistics from Brown University, followed by a PhD in Linguistics at the University of California San Diego and postdoctoral fellowships at Northwestern and Stanford. She has helped organise the EU-wide "TextLink: Structuring discourse in multilingual Europe" COST Action network and is a recipient of the Philip Leverhulme Prize in Languages and Literatures.  Her dream is to one day experience in-person conferences again – to indulge in standing around in overcrowded corridors, talking to interesting people over conference coffee and biscuits!

</details>

<details open><summary><strong>15:00-15:25 Plenary session: Tasks 8, 9, 12</strong></summary>

 - _SemEval-2021 Task 8: MeasEval – Extracting Counts and Measurements and their Related Contexts_, Corey Harper, Jessica Cox, Curt Kohler, Antony Scerri, Ron Daniel Jr. and Paul Groth
 - _SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS)_, Nancy X. R. Wang, Diwakar Mahajan, Marina Danilevsky and Sara Rosentha
 - _BreakingBERT@IITK at SemEval-2021 Task 9: Statement Verification and Evidence Finding with Tables_, Aditya Jindal, Ankur Gupta, Jaya Srivastava, Preeti Menghwani, Vijit Malik, Vishesh Kaushik and Ashutosh Modi
 - _SemEval-2021 Task 12: Learning with Disagreements_, Alexandra Uma, Tommaso Fornaciari, Anca Dumitrache, Tristan Miller, Jon Chamberlain, Barbara Plank, Edwin Simpson and Massimo Poesio

</details>

<details open><summary><strong>15:25-15:50 Plenary session: Tasks 10, 11</strong></summary>

 - _SemEval-2021 Task 10: Source-Free Domain Adaptation for Semantic Processing_, Egoitz Laparra, Xin Su, Yiyun Zhao, Özlem Uzuner, Timothy Miller and Steven Bethard
 - _BLCUFIGHT at SemEval-2021 Task 10: Novel Unsupervised Frameworks For Source-Free Domain Adaptation_, Weikang Wang, Yi Wu, Yixiang Liu and Pengyuan Liu
 - _SemEval-2021 Task 11: NLPContributionGraph - Structuring Scholarly NLP Contributions for a Research Knowledge Graph_, Jennifer D'Souza, Sören Auer and Ted Pedersen
 - _UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for Structuring Scholarly NLP Contributions_, Haoyang Liu, M. Janina Sarol and Halil Kilicoglu

</details>

<details><summary><strong>15:50-16:00 Announcement of SemEval-2022 Tasks & Closing Remarks</strong></summary>
  To be announced!
</details>

<details><summary><strong>02:00-03:00(🌻) / 11:30-12:30(🌳) / 16:30-17:30(🍄) Poster session: Tasks 8, 9, 12</strong></summary>

 - #115 _KGP at SemEval-2021 Task 8: Leveraging Multi-Staged Language Models for Extracting Measurements, their Attributes and Relations_, Neel Karia, Ayush Kaushal and Faraaz Mallick 🌳🍄
 - #154 _DPR at SemEval-2021 Task 8: Dynamic Path Reasoning for Measurement Relation Extraction_, Amir Pouran Ben Veyseh, Franck Dernoncourt and Thien Huu Nguyen 🌳
 - #171 _CLaC-np at SemEval-2021 Task 8: Dependency DGCNN_, Nihatha Lathiff, Pavel Khloponin and Sabine Bergler 🌳🍄
 - #174 _CLaC-BP at SemEval-2021 Task 8: SciBERT Plus Rules for MeasEval_, Benjamin Therien, Parsa Bagherzadeh and Sabine Bergler 🌳🍄
 - #63 _BreakingBERT@IITK at SemEval-2021 Task 9: Statement Verification and Evidence Finding with Tables_, Aditya Jindal, Ankur Gupta, Jaya Srivastava, Preeti Menghwani, Vijit Malik, Vishesh Kaushik and Ashutosh Modi 🌻🍄
 - #104 _THiFly_Queens at SemEval-2021 Task 9: Two-stage Statement Verification with Adaptive Ensembling and Slot-based Operation_, Yuxuan Zhou, Kaiyin Zhou, Xien Liu, Ji Wu and Xiaodan Zhu 🌻
 - #112 _TAPAS at SemEval-2021 Task 9: Reasoning over tables with intermediate pre-training_, Thomas Müller, Julian Eisenschlos and Syrine Krichene 🌳
 - #199 _BOUN at SemEval-2021 Task 9: Text Augmentation Techniques for Fact Verification in Tabular Data_, Abdullatif Köksal, Yusuf Yüksel, Bekir Yıldırım and Arzucan Özgür 🌳🍄

</details>

<details><summary><strong>03:00-04:00(🌻) / 12:30-13:30(🌳) / 17:30-18:30(🍄) Poster session: Tasks 10, 11</strong></summary>

 - #93 _IITK at SemEval-2021 Task 10: Source-Free Unsupervised Domain Adaptation using Class Prototypes_, Harshit Kumar, Jinang Shah, Nidhi Hegde, Priyanshu Gupta, Vaibhav Jindal and Ashutosh Modi 🌳
 - #105 _PTST-UoM at SemEval-2021 Task 10: Parsimonious Transfer for Sequence Tagging_, Kemal Kurniawan, Lea Frermann, Philip Schulz and Trevor Cohn 🌻🌳
 - #106 _BLCUFIGHT at SemEval-2021 Task 10: Novel Unsupervised Frameworks For Source-Free Domain Adaptation_, Weikang Wang, Yi Wu, Yixiang Liu and pengyuan liu 
 - #125 _Self-Adapter at SemEval-2021 Task 10: Entropy-based Pseudo-Labeler for Source-free Domain Adaptation_, Sangwon Yoon, Yanghoon Kim and Kyomin Jung 🌻🌳🍄
 - #151 _The University of Arizona at SemEval-2021 Task 10: Applying Self-training, Active Learning and Data Augmentation to Source-free Domain Adaptation_, Xin Su, Yiyun Zhao and Steven Bethard 🌻🍄
 - #49 _KnowGraph@IITK at SemEval-2021 Task 11: Building Knowledge Graph for NLP Research_, Shashank Shailabh, Sajal Chaurasia and Ashutosh Modi 🌳
 - #95 _YNU-HPCC at SemEval-2021 Task 11: Using a BERT Model to Extract Contributions from NLP Scholarly Articles_, Xinge Ma, Jin Wang and Xuejie Zhang 🌻🍄
 - #103 _ITNLP at SemEval-2021 Task 11: Boosting BERT with Sampling and Adversarial Training for Knowledge Extraction_, Genyu Zhang, Yu Su, Changhong He, Lei Lin, Chengjie Sun and Lili Shan 🌻
 - #172 _UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for Structuring Scholarly NLP Contributions_, Haoyang Liu, M. Janina Sarol and Halil Kilicoglu 🌳🍄
 - #185 _Duluth at SemEval-2021 Task 11: Applying DeBERTa to Contributing Sentence Selection and Dependency Parsing for Entity Extraction_, Anna Martin and Ted Pedersen 🌳
 - #197 _INNOVATORS at SemEval-2021 Task-11: A Dependency Parsing and BERT-based model for Extracting Contribution Knowledge from Scientific Papers_, Hardik Arora, Tirthankar Ghosal, Sandeep Kumar, Suraj Patwal and Phil Gooch 🌻🍄

</details>
